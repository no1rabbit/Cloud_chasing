{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7f747f-4b81-4b61-946c-80c00b1f494d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import rioxarray\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from deafrica_tools.spatial import xr_rasterize\n",
    "serengeti = gpd.read_file('data/serengeti.geojson')\n",
    "serengeti = serengeti.to_crs('epsg:21036')\n",
    "serengeti\n",
    "#mask = xr_rasterize(serengeti[serengeti['ID'] == 0], ds_rf)\n",
    "\n",
    "#mask the rainfall dataset\n",
    "#ds_rf = ds_rf.where(mask)\n",
    "\n",
    "# Plot the mask\n",
    "#mask.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab02eaa0-0200-43e3-99d0-93ddff834c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the NetCDF file using xarray\n",
    "ds = xr.open_dataset('data/Serengeti_tamsat.nc')\n",
    "ds = ds.sel(time=slice('2015-01', '2022-09'))\n",
    "#ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22bbaac-24fd-4c94-b343-b2b5811ed8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.rio.set_spatial_dims('lon','lat',inplace=True)\n",
    "ds.rio.write_crs('EPSG:4326',inplace=True)\n",
    "ds = ds.rio.reproject(\"EPSG:21036\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = xr_rasterize(serengeti[serengeti['ID'] == 0], ds)\n",
    "\n",
    "#mask the rainfall dataset\n",
    "ds = ds.where(mask)\n",
    "\n",
    "# Plot the mask\n",
    "mask.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea62108f-c1cc-4cfd-9266-442028b6fe90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds.rfe.sel(time=slice('2016-11-20', '2016-12-01')).plot(col='time', col_wrap=5, add_colorbar=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54fab0a-2607-499d-a906-79e8fde15c8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the threshold value\n",
    "threshold = 5.0\n",
    "\n",
    "# Find the time, latitude, and longitude when rainfall is above the threshold\n",
    "ds_masked = ds['rfe'].where(ds['rfe'] > threshold, drop=True)\n",
    "ds_masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b773895-c926-45a3-b3c4-bc920805ef6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file = \"data/Serengeti_all.csv\"\n",
    "dfa = pd.read_csv(file, dtype=None)\n",
    "\n",
    "dfa['time1'] = pd.to_datetime(dfa['t1_'])\n",
    "dfa['date1'] = pd.to_datetime(dfa['time1'].dt.date)\n",
    "dfa['time2'] = pd.to_datetime(dfa['t2_'])\n",
    "dfa['date2'] = pd.to_datetime(dfa['time2'].dt.date)\n",
    "\n",
    "# Subset the DataFrame by the date range\n",
    "dfa.set_index('date1', inplace=True)\n",
    "dfa = dfa.sort_index()\n",
    "#df = df['2013-11-11':'2013-11-16']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4e4fb8-321d-4c2a-a3ac-f481c19a99a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matplotlib.patches import FancyArrowPatch\n",
    "\n",
    "dfs = dfa['2016-11-20':'2016-12-01']\n",
    "dm = ds_masked.sel(time=slice('2016-11-20', '2016-12-01'))\n",
    "dm.plot(col='time', col_wrap=3 )\n",
    "\n",
    "# Get the list of axes from the xarray subplot grid\n",
    "axes = plt.gcf().get_axes()\n",
    "\n",
    "# Extract unique IDs from the GPS data\n",
    "unique_ids = dfs['ID'].unique()\n",
    "\n",
    "# Define a mapping between IDs and colors\n",
    "id_color_map = {}\n",
    "colors = plt.cm.get_cmap('magma', len(unique_ids))\n",
    "\n",
    "for i, id in enumerate(unique_ids):\n",
    "    id_color_map[id] = colors(i)\n",
    "\n",
    "# Overlay GPS data on each subplot, coloring by ID and case_\n",
    "for i, ax in enumerate(axes):\n",
    "    if i < len(dm['time']):  # Check if the index is within bounds\n",
    "        # Extract the time for the current subplot\n",
    "        current_time = dm['time'][i].values\n",
    "        \n",
    "        # Filter GPS data for the current time using .loc\n",
    "        gps_data_subset = dfs.loc[dfs.index == current_time]\n",
    "        \n",
    "        # Iterate over unique IDs and plot each group with a unique color\n",
    "        for id in unique_ids:\n",
    "            id_subset = gps_data_subset[gps_data_subset['ID'] == id]\n",
    "            color = id_color_map[id]\n",
    "            # Separate the data based on 'case_' values\n",
    "            case_true_data = id_subset[id_subset['case_']]\n",
    "            case_false_data = id_subset[~id_subset['case_']]\n",
    "            # Plot the first set of X and Y data (x1_ and y1_) with different colors\n",
    "            ax.scatter(case_true_data['x1_'], case_true_data['y1_'], color=color, label=f'ID {id} (Case True)', s=20)\n",
    "            #ax.scatter(case_false_data['x1_'], case_false_data['y1_'], color=color, label=f'ID {id} (Case False)', s=20)\n",
    "            # Plot the second set of X and Y data (x2_ and y2_) with different colors\n",
    "            ax.scatter(case_true_data['x2_'], case_true_data['y2_'], color=color, s=20)\n",
    "            #ax.scatter(case_false_data['x2_'], case_false_data['y2_'], color=color, s=20)\n",
    "            # Connect the points with lines for both sets of data\n",
    "            for index, row in case_true_data.iterrows():\n",
    "                ax.add_patch(FancyArrowPatch((row['x1_'], row['y1_']), (row['x2_'], row['y2_']),\n",
    "                                             arrowstyle='->', color=color, mutation_scale=10))\n",
    "            #for index, row in case_false_data.iterrows():\n",
    "                #ax.add_patch(FancyArrowPatch((row['x1_'], row['y1_']), (row['x2_'], row['y2_']),\n",
    "                                             #arrowstyle='->', color='grey', mutation_scale=15))\n",
    "        \n",
    "        # Set the x and y axis limits for zooming\n",
    "        #ax.set_xlim(596742, 821598)\n",
    "        #ax.set_ylim(9608997.0, 9879023)\n",
    "        #ax.legend()\n",
    "        #ax.set_title(f'GPS Data Overlay at Time {current_time}')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1d7ac4-c413-4467-82b2-36ac48708169",
   "metadata": {},
   "outputs": [],
   "source": [
    "## datasets for cloud calculation\n",
    "df = dfa.reset_index()\n",
    "rain = ds_masked.to_dataframe().reset_index()\n",
    "rain = rain.dropna()\n",
    "rain['date'] = pd.to_datetime(rain['time'].dt.date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "subset the data for 2 months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a476824-d219-455d-8ea2-e8f14f136754",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = dfa['2016-10-01':'2016-11-30']\n",
    "dm = ds_masked.sel(time=slice('2016-10-01', '2016-11-30'))\n",
    "df = dfs.reset_index()\n",
    "rain = dm.to_dataframe().reset_index()\n",
    "rain = rain.dropna()\n",
    "rain['date'] = pd.to_datetime(rain['time'].dt.date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2493dc-42ac-4d6f-92ed-4d9a5e2fc3ee",
   "metadata": {},
   "source": [
    "# Find best cloud pixel based on distance and estimated rainfall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "from tqdm import tqdm  # Import tqdm for the progress bar\n",
    "\n",
    "# Assuming your GPS DataFrame is named df and rainfall DataFrame is named rain\n",
    "\n",
    "# Set up tqdm for the loop\n",
    "tqdm.pandas()\n",
    "\n",
    "def calculate_angle(row):\n",
    "    trajectory_vector = np.array([row['x2_'] - row['x1_'], row['y2_'] - row['y1_']])\n",
    "    cloud_vector = np.array([row['best_pixel_x'] - row['x1_'], row['best_pixel_y'] - row['y1_']])\n",
    "    \n",
    "    dot_product = np.dot(trajectory_vector, cloud_vector)\n",
    "    norm_product = np.linalg.norm(trajectory_vector) * np.linalg.norm(cloud_vector)\n",
    "    cloud_dist = np.linalg.norm(cloud_vector)\n",
    "    \n",
    "    cloud_angle = np.arccos(dot_product / norm_product)\n",
    "    cos_cloud_angle = np.cos(cloud_angle)\n",
    "\n",
    "    return dot_product, cloud_angle, cos_cloud_angle, cloud_dist\n",
    "\n",
    "# Create a progress bar for the loop\n",
    "for index, gps_row in tqdm(df.iterrows(), total=len(df), desc=\"Processing GPS Data\"):\n",
    "    # 1. Find corresponding date in rainfall DataFrame\n",
    "    date = gps_row['date1']\n",
    "    rainfall_date = rain[rain['date'] == date]\n",
    "\n",
    "    # 2. Subset the rainfall data for that specific date\n",
    "    rainfall_subset = rainfall_date.copy()\n",
    "\n",
    "    # 3. Calculate distance between GPS location and each pixel\n",
    "    gps_location = np.array([gps_row['x1_'], gps_row['y1_']])\n",
    "    rainfall_subset['distance'] = cdist(rainfall_subset[['x', 'y']], [gps_location],'euclidean')/1000\n",
    "\n",
    "    # 4. Score each pixel based on the criteria\n",
    "    rainfall_subset['score'] = 1 / rainfall_subset['distance'] * rainfall_subset['rfe']\n",
    "\n",
    "    # 5. Check if there are valid pixels in rainfall_subset\n",
    "    if not rainfall_subset.empty:\n",
    "        # 6. Find the pixel with the highest score\n",
    "        best_pixel = rainfall_subset.loc[rainfall_subset['score'].idxmax()]\n",
    "\n",
    "        # 7. Add the corresponding rainfall estimate to your GPS DataFrame\n",
    "        df.at[index, 'best_rainfall'] = best_pixel['rfe']\n",
    "        df.at[index,'rain_date'] = best_pixel['date']\n",
    "\n",
    "        # 8. Add the location of the best pixel to your GPS DataFrame\n",
    "        df.at[index, 'best_pixel_x'] = best_pixel['x']\n",
    "        df.at[index, 'best_pixel_y'] = best_pixel['y']\n",
    "\n",
    "    else:\n",
    "        # Handle the case where rainfall_subset is empty (no valid pixels for the given date)\n",
    "        # You might want to set some default values or handle it in a way that makes sense for your use case\n",
    "        df.at[index, 'best_rainfall'] = np.nan\n",
    "        df.at[index, 'best_pixel_x'] = np.nan\n",
    "        df.at[index, 'best_pixel_y'] = np.nan\n",
    "        \n",
    "# Create a progress bar for the loop\n",
    "for index, gps_row in tqdm(df.iterrows(), total=len(df), desc=\"Processing turning angle\"):\n",
    "    # 9. Calculate angles and distance\n",
    "    dot_product, cloud_angle, cos_cloud_angle, cloud_dist = calculate_angle(gps_row)\n",
    "    df.at[index, 'dot_product'] = dot_product\n",
    "    df.at[index, 'cloud_angle'] = cloud_angle\n",
    "    df.at[index, 'cos_cloud_angle'] = cos_cloud_angle\n",
    "    df.at[index, 'cloud_dist'] = cloud_dist\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1953408b-df7f-462b-9e43-e18fa8f7a9b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Plot the nearest cloud of different thresholds\n",
    "from matplotlib.patches import FancyArrowPatch\n",
    "\n",
    "#dfs = df['2013-11-20':'2013-11-27']\n",
    "dfd = df\n",
    "dfd.set_index('date1', inplace=True)\n",
    "dfd = dfd['2016-11-20':'2016-11-27']\n",
    "dfd = dfd[dfd['ID'] == 'SW37']\n",
    "#dfd.set_index('date1', inplace=True)\n",
    "dm = ds_masked.sel(time=slice('2016-11-20', '2016-11-27'))\n",
    "dm.plot(col='time', col_wrap=2 )\n",
    "#dfcloud = df\n",
    "\n",
    "# Get the list of axes from the xarray subplot grid\n",
    "axes = plt.gcf().get_axes()\n",
    "\n",
    "# Extract unique IDs from the GPS data\n",
    "#unique_ids = dfs['ID'].unique()\n",
    "unique_ids = df['ID'].unique()\n",
    "\n",
    "# Define a mapping between IDs and colors\n",
    "id_color_map = {}\n",
    "colors = plt.cm.get_cmap('magma', len(unique_ids))\n",
    "\n",
    "for i, id in enumerate(unique_ids):\n",
    "    id_color_map[id] = colors(i)\n",
    "\n",
    "# Overlay GPS data on each subplot, coloring by ID and case_\n",
    "for i, ax in enumerate(axes):\n",
    "    if i < len(dm['time']):  # Check if the index is within bounds\n",
    "        # Extract the time for the current subplot\n",
    "        current_time = dm['time'][i].values\n",
    "        \n",
    "        # Filter GPS data for the current time using .loc\n",
    "        #gps_data_subset = dfs.loc[dfs.index == current_time]\n",
    "        gps_data_subset = dfd.loc[dfd.index == current_time]\n",
    "        \n",
    "        # Iterate over unique IDs and plot each group with a unique color\n",
    "        for id in unique_ids:\n",
    "            id_subset = gps_data_subset[gps_data_subset['ID'] == id]\n",
    "            color = id_color_map[id]\n",
    "            # Separate the data based on 'case_' values\n",
    "            case_true_data = id_subset[id_subset['case_']]\n",
    "            case_false_data = id_subset[~id_subset['case_']]\n",
    "            # Plot the first set of X and Y data (x1_ and y1_) with different colors\n",
    "            ax.scatter(case_true_data['x1_'], case_true_data['y1_'], color=color, label=f'ID {id} (Case True)', s=20)\n",
    "            #ax.scatter(case_false_data['x1_'], case_false_data['y1_'], color=color, label=f'ID {id} (Case False)', s=20)\n",
    "            # Plot the second set of X and Y data (x2_ and y2_) with different colors\n",
    "            ax.scatter(case_true_data['x2_'], case_true_data['y2_'], color=color, s=20)\n",
    "            #ax.scatter(case_false_data['x2_'], case_false_data['y2_'], color=color, s=20)\n",
    "            ax.scatter(case_true_data['best_pixel_x'], case_true_data['best_pixel_y'], color='red', s=20)\n",
    "            #ax.scatter(case_true_data['cloud_8mm_x'], case_true_data['cloud_8mm_y'], color='green', s=20)\n",
    "            #ax.scatter(case_true_data['cloud_10mm_x'], case_true_data['cloud_10mm_y'], color='yellow', s=20)\n",
    "            #ax.scatter(case_true_data['cloud4_x'], case_true_data['cloud4_y'], color='orange', s=20)\n",
    "            #ax.scatter(case_true_data['cloud5_x'], case_true_data['cloud5_y'], color='brown', s=20)\n",
    "            # Connect the points with lines for both sets of data\n",
    "            for index, row in case_true_data.iterrows():\n",
    "                ax.add_patch(FancyArrowPatch((row['x1_'], row['y1_']), (row['x2_'], row['y2_']),\n",
    "                                             arrowstyle='->', color=color, mutation_scale=10))\n",
    "            #for index, row in case_false_data.iterrows():\n",
    "                #ax.add_patch(FancyArrowPatch((row['x1_'], row['y1_']), (row['x2_'], row['y2_']),\n",
    "                                             #arrowstyle='->', color='grey', mutation_scale=15))\n",
    "        # Set the x and y axis limits for zooming\n",
    "        #ax.set_xlim(596742, 821598)\n",
    "        #ax.set_ylim(9608997.0, 9879023)\n",
    "        #ax.legend()\n",
    "        #ax.set_title(f'GPS Data Overlay at Time {current_time}')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb55c16e-e39e-41f5-b3e7-21024e9b947f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/Serengeti.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "from tqdm import tqdm  # Import tqdm for the progress bar\n",
    "\n",
    "# Set up tqdm for the loop\n",
    "tqdm.pandas()\n",
    "\n",
    "#dfs = df['2013-11-20':'2013-11-27']\n",
    "dfd = df.set_index('date1', inplace=True)\n",
    "dfd = dfd['2016-11-20':'2016-11-20']\n",
    "dfd = dfd[dfd['ID'] == 'SW37']\n",
    "\n",
    "# Create a progress bar for the loop\n",
    "for index, gps_row in tqdm(dfd.iterrows(), total=len(dfd), desc=\"Processing GPS Data\"):\n",
    "    # 1. Find corresponding date in rainfall DataFrame\n",
    "    date = gps_row['date1']\n",
    "    rainfall_date = rain[rain['date'] == date]\n",
    "\n",
    "    # 2. Subset the rainfall data for that specific date\n",
    "    rainfall_subset = rainfall_date.copy()\n",
    "\n",
    "    # 3. Calculate distance between GPS location and each pixel\n",
    "    gps_location = np.array([gps_row['x1_'], gps_row['y1_']])\n",
    "    rainfall_subset['distance'] = cdist(rainfall_subset[['x', 'y']], [gps_location])\n",
    "\n",
    "    # 4. Score each pixel based on the criteria\n",
    "    rainfall_subset['score'] = 1 / rainfall_subset['distance'] * rainfall_subset['rfe']\n",
    "\n",
    "print(rainfall_subset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
